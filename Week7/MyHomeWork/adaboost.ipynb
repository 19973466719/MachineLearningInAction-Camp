{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 收集数据：可以使用任意方法。\n",
    "2. 准备数据：依赖于所使用的弱分类器类型，本章使用的是单层决策树，这种分类器可以处理任何数据类型。当然也可以使用任意分类器作为弱分类器，第2章到第6章中的任一分类器都可以充当弱分类器。作为弱分类器，简单分类器的效果更好。\n",
    "3. 分析数据：可以使用任意方法。\n",
    "4. 训练算法： AdaBoost的大部分时间都用在训练上，分类器将多次在同一数据集上训练弱分类器。\n",
    "5. 测试算法：计算分类的错误率。\n",
    "6. 使用算法：同SVM一样， AdaBoost预测两个类别中的一个。如果想把它应用到多个类别的场合，那么就要像多类SVM中的做法一样对AdaBoost进行修改。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练算法：基于错误提升分类器的性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化数据\n",
    "def loadSimpData():\n",
    "    datMat = np.matrix([[1, 2.1],\n",
    "                        [2, 1.1],\n",
    "                        [1.3, 1],\n",
    "                        [1, 1],\n",
    "                        [2, 1]])\n",
    "    classLabels = [1, 1, -1, -1, 1]\n",
    "    return datMat, classLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datMat, classLabels = loadSimpData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建单层决策树\n",
    "程序伪代码：  \n",
    "将最小错误率minError设为$+\\infty$  \n",
    "对数据集中的每一个特征（第一层循环）：  \n",
    "&emsp;&emsp;对每个步长（第二层循环）：  \n",
    "&emsp;&emsp;&emsp;&emsp;对每个不等号（第三层循环）：  \n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;建立一棵单层决策树并利用加权数据集对它进行测试  \n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;如果错误率低于minError，则将当前单层决策树设为最佳单层决策树  \n",
    "返回最佳单层决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单层决策树生成函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过阈值比较对数据进行分类\n",
    "def stumpClassify(dataMatrix, dimen, threshVal, threshIneq):\n",
    "    # 将返回数组中的全部元素设置为1\n",
    "    retArray = np.ones((np.shape(dataMatrix)[0], 1))\n",
    "    # 所有满足不等式要求的元素设置为-1\n",
    "    if threshIneq == 'lt':\n",
    "        retArray[dataMatrix[:, dimen] <= threshVal] = -1\n",
    "    else:\n",
    "        retArray[dataMatrix[:, dimen] > threshVal] = -1\n",
    "    return retArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历所有的可能输入值，并找到数据集上最佳的单层决策树\n",
    "def buildStump(dataArr, classLabels, D):\n",
    "    # 将数据矩阵化\n",
    "    dataMatrix = np.mat(dataArr); labelMat = np.mat(classLabels).T\n",
    "    m, n = np.shape(dataMatrix)\n",
    "    # bestStump 用于存储给定权重向量D时所得到的最佳单层决策树的相关信息\n",
    "    # numSteps 用于在特征的所有可能值上进行遍历\n",
    "    numSteps = 10; bestStump = {}; bestClasEst =np.mat(np.zeros((m, 1)))\n",
    "    # 一开始就初始化成正无穷大，用于寻找可能的最小错误率\n",
    "    minError = np.Inf\n",
    "    # 在所有特征上遍历\n",
    "    for i in range(n):\n",
    "        rangeMin = dataMatrix[:, i].min(); rangeMax = dataMatrix[:, i].max();\n",
    "        # 计算得到步长\n",
    "        stepSize = (rangeMax - rangeMin) / numSteps\n",
    "        # 从最左边开始设置阈值，-1的目的是从一开始就将最小点归为右侧\n",
    "        for j in range(-1, int(numSteps) + 1):\n",
    "            for inequal in ['lt', 'gt']:\n",
    "                # 设置阈值\n",
    "                threshVal = rangeMin + float(j) * stepSize\n",
    "                predictedVals = stumpClassify(dataMatrix, i, threshVal, inequal)\n",
    "                errArr = np.mat(np.ones((m, 1)))\n",
    "                # 如果predictedVals中的值不等于labelMat中的真正类别标签值，就设置为1\n",
    "                # 否则设置为0\n",
    "                errArr[predictedVals == labelMat] = 0\n",
    "                weightedError = D.T * errArr\n",
    "                #print(\"split: dim %d, thresh %.2f, thresh ineqal: %s, the weighted error is %.3f\" % (i, threshVal, inequal, weightedError))\n",
    "                if weightedError < minError:\n",
    "                    minError = weightedError\n",
    "                    bestClasEst = predictedVals.copy()\n",
    "                    bestStump['dim'] = i\n",
    "                    bestStump['thresh'] = threshVal\n",
    "                    bestStump['ineq'] = inequal\n",
    "    return bestStump, minError, bestClasEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.mat(np.ones((5, 1)) / 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'dim': 0, 'thresh': 1.3, 'ineq': 'lt'}, matrix([[0.2]]), array([[-1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [ 1.]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buildStump(datMat, classLabels, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完整AdaBoost算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "伪代码：  \n",
    "对每次迭代：  \n",
    "&emsp;&emsp;利用buildStump()函数找到最佳的单层决策树  \n",
    "&emsp;&emsp;将最佳单层决策树加入到单层决策树数组  \n",
    "&emsp;&emsp;计算alpha  \n",
    "&emsp;&emsp;计算新的权重向量D\n",
    "&emsp;&emsp;更新累计类别估计值\n",
    "&emsp;&emsp;如果错误率等于0.0，则退出循环"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于单层决策树的AdaBoost训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataArr 数据集，classLabels 类别标签, numIt 迭代次数\n",
    "def adaBoostTrainDS(dataArr, classLabels, numIt=40):\n",
    "    weakClassArr = []\n",
    "    m = np.shape(dataArr)[0]\n",
    "    # D是一个概率分布向量，所有的元素之和为1.0\n",
    "    D = np.mat(np.ones((m, 1)) / m)\n",
    "    # 记录每个数据点的类别估计累计值\n",
    "    aggClassEst = np.mat(np.zeros((m, 1)))\n",
    "    for i in range(numIt):\n",
    "        #返回最小错误率的单层决策树，最小错误率，估计的类别向量\n",
    "        bestStump, error, classEst = buildStump(dataArr, classLabels, D)\n",
    "        print(\"D: \", D.T)\n",
    "        # 计算alpha值\n",
    "        alpha = float(0.5 * np.log((1.0 - error)/ max(error, 1e-16)))\n",
    "        bestStump['alpha'] = alpha\n",
    "        weakClassArr.append(bestStump)\n",
    "        print(\"classEst: \", classEst.T)\n",
    "        # 计算下一次迭代的D\n",
    "        expon = np.multiply(-1 * alpha * np.mat(classLabels).T, classEst)\n",
    "        D = np.multiply(D, np.exp(expon))\n",
    "        D = D / D.sum()\n",
    "        # 错误率累加计算\n",
    "        aggClassEst += alpha * classEst\n",
    "        print(\"aggClassEst: \", aggClassEst.T)\n",
    "        aggErrors = np.multiply(np.sign(aggClassEst) != np.mat(classLabels).T, np.ones((m, 1)))\n",
    "        errorRate = aggErrors.sum() / m\n",
    "        print(\"total error: \", errorRate, \"\\n\")\n",
    "        if errorRate == 0.0: break\n",
    "    return weakClassArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:  [[0.2 0.2 0.2 0.2 0.2]]\n",
      "classEst:  [[-1.  1. -1. -1.  1.]]\n",
      "aggClassEst:  [[-0.69314718  0.69314718 -0.69314718 -0.69314718  0.69314718]]\n",
      "total error:  0.2 \n",
      "\n",
      "D:  [[0.5   0.125 0.125 0.125 0.125]]\n",
      "classEst:  [[ 1.  1. -1. -1. -1.]]\n",
      "aggClassEst:  [[ 0.27980789  1.66610226 -1.66610226 -1.66610226 -0.27980789]]\n",
      "total error:  0.2 \n",
      "\n",
      "D:  [[0.28571429 0.07142857 0.07142857 0.07142857 0.5       ]]\n",
      "classEst:  [[1. 1. 1. 1. 1.]]\n",
      "aggClassEst:  [[ 1.17568763  2.56198199 -0.77022252 -0.77022252  0.61607184]]\n",
      "total error:  0.0 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'dim': 0, 'thresh': 1.3, 'ineq': 'lt', 'alpha': 0.6931471805599453},\n",
       " {'dim': 1, 'thresh': 1.0, 'ineq': 'lt', 'alpha': 0.9729550745276565},\n",
       " {'dim': 0, 'thresh': 0.9, 'ineq': 'lt', 'alpha': 0.8958797346140273}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaBoostTrainDS(datMat, classLabels, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试算法：基于AdaBoost的分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datToClass一个或多个待分类样例，classifierArr多个弱分类器\n",
    "def adaClassify(datToClass, classifierArr):\n",
    "    dataMatrix = np.mat(datToClass)\n",
    "    m = np.shape(dataMatrix)[0]\n",
    "    aggClassEst = np.mat(np.zeros((m, 1)))\n",
    "    for i in range(len(classifierArr)):\n",
    "        classEst = stumpClassify(dataMatrix, classifierArr[i]['dim'], classifierArr[i]['thresh'], classifierArr[i]['ineq'])\n",
    "        aggClassEst += classifierArr[i]['alpha'] * classEst\n",
    "        print(aggClassEst)\n",
    "    return np.sign(aggClassEst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datArr, labelArr = loadSimpData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:  [[0.2 0.2 0.2 0.2 0.2]]\n",
      "classEst:  [[-1.  1. -1. -1.  1.]]\n",
      "aggClassEst:  [[-0.69314718  0.69314718 -0.69314718 -0.69314718  0.69314718]]\n",
      "total error:  0.2 \n",
      "\n",
      "D:  [[0.5   0.125 0.125 0.125 0.125]]\n",
      "classEst:  [[ 1.  1. -1. -1. -1.]]\n",
      "aggClassEst:  [[ 0.27980789  1.66610226 -1.66610226 -1.66610226 -0.27980789]]\n",
      "total error:  0.2 \n",
      "\n",
      "D:  [[0.28571429 0.07142857 0.07142857 0.07142857 0.5       ]]\n",
      "classEst:  [[1. 1. 1. 1. 1.]]\n",
      "aggClassEst:  [[ 1.17568763  2.56198199 -0.77022252 -0.77022252  0.61607184]]\n",
      "total error:  0.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifierArr = adaBoostTrainDS(datArr, labelArr, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.69314718]]\n",
      "[[-1.66610226]]\n",
      "[[-2.56198199]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[-1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaClassify([0, 0], classifierArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.69314718]\n",
      " [-0.69314718]]\n",
      "[[ 1.66610226]\n",
      " [-1.66610226]]\n",
      "[[ 2.56198199]\n",
      " [-2.56198199]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.],\n",
       "        [-1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaClassify([[5, 5], [0, 0]], classifierArr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
