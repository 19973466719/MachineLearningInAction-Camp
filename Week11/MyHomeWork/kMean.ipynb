{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# K-均值聚类算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**优点：**容易实现。  \n",
    "**缺点：**可能收敛到局部最小值，在大规模数据集上收敛较慢。   \n",
    "**适用数据类型：**数值型数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "伪代码：  \n",
    "创建$k$个点作为起始质心（经常是随机选择）  \n",
    "当任意一个点的簇分配结构发生改变时  \n",
    "&emsp;&emsp;对数据集中的每个数据点  \n",
    "&emsp;&emsp;&emsp;&emsp;对每个质心  \n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;计算质心与数据点之间的距离  \n",
    "&emsp;&emsp;&emsp;&emsp;将数据点分配到距其最近的簇  \n",
    "&emsp;&emsp;对每一个簇，计算簇中所有点的均值并将均值作为质心"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**一般流程**  \n",
    "1. 收集数据：使用任意方法。\n",
    "2. 准备数据：需要数值型数据来计算距离，也可以将标称型数据映射为二值型数据再用于距离计算。\n",
    "3. 分析数据：使用任意方法。\n",
    "4. 训练算法：不适用于无监督学习，即无监督学习没有训练过程。\n",
    "5. 测试算法：应用聚类算法、观察结果。可以使用量化的误差指标如误差平方和（后面会介绍）来评价算法的结果。\n",
    "6. 使用算法：可以用于所希望的任何应用。通常情况下，簇质心可以代表整个簇的数据来做出决策。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-均值聚类支持函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将文本导入到一个列表中。\n",
    "def loadDataSet(fileName):\n",
    "    dataMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        curLine = line.strip().split('\\t')\n",
    "        fltLine = list(map(float, curLine))\n",
    "        dataMat.append(fltLine)\n",
    "    return dataMat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "两个向量的欧式距离公式：$d_{12}=\\sqrt{\\sum_{k=1}^n(x_{1k}-x_{2k})^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算两个向量的欧式距离\n",
    "def distEclud(vecA, vecB):\n",
    "    return np.sqrt(np.sum(np.power(vecA - vecB, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为给定数据集构建一个包含k个随机质心的集合。\n",
    "# 随机质心必须要在整个数据集的边界之内。\n",
    "def randCent(dataSet, k):\n",
    "    # 获得dataSet的维度\n",
    "    n = np.shape(dataSet)[1]\n",
    "    # 创建k行n列的向量\n",
    "    centroids = np.mat(np.zeros((k, n)))\n",
    "    for j in range(n):\n",
    "        # 获取该列的最小值\n",
    "        minJ = min(dataSet[:, j])\n",
    "        # 获取该列的范围\n",
    "        rangeJ = float(max(dataSet[:, j]) - minJ)\n",
    "        # 获取随机的列数据，并确保在边界值内\n",
    "        centroids[:, j] = minJ + rangeJ * np.random.rand(k, 1)\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试三个函数的实际效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datMat = np.mat(loadDataSet('testSet.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-5.379713]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(datMat[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-4.232586]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(datMat[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[5.1904]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(datMat[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[4.838138]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(datMat[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-3.20342207,  1.66863242],\n",
       "        [-4.72757408,  5.07705288]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randCent(datMat, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.184632816681332"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distEclud(datMat[0], datMat[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备实现完整的K-均值算法。该算法会常见$k$个质心，然后将每个点分配到最近的质心，再重新计算质心。这个过程重复数次，直到数据点的簇分配结果不再改变为止。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-均值聚类算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataSet: 数据集，k: 簇的数目， distMeas: 用来计算距离的函数，createCent: 用来创建初始质心的函数\n",
    "def kMeans(dataSet, k, distMeas=distEclud, createCent=randCent):\n",
    "    # 确定数据集中数据点的总数\n",
    "    m = np.shape(dataSet)[0]\n",
    "    # 创建一个矩阵来存储每个点的簇分配结果\n",
    "    # 包括两列： 第一列记录簇索引值，第二列存储误差（当前点到簇质心的距离）\n",
    "    clusterAssment = np.mat(np.zeros((m, 2)))\n",
    "    # 初始化创建k个质心\n",
    "    centroids = createCent(dataSet, k)\n",
    "    # 设置聚类是否改变的标志变量\n",
    "    clusterChanged = True\n",
    "    while clusterChanged:\n",
    "        clusterChanged = False\n",
    "        for i in range(m):\n",
    "            minDist = np.inf; minIndex = -1\n",
    "            # 寻找最近的质心\n",
    "            for j in range(k):\n",
    "                distJI = distMeas(centroids[j, :], dataSet[i, :])\n",
    "                if distJI < minDist:\n",
    "                    minDist = distJI; minIndex = j\n",
    "            # 判断是否最近质心变了\n",
    "            if clusterAssment[i, 0] != minIndex:\n",
    "                clusterChanged = True\n",
    "            # 对误差取平方的目的是更加重视那些远离中心的点\n",
    "            clusterAssment[i, :] = minIndex, minDist**2\n",
    "        print(centroids)\n",
    "        # 更新质心的位置\n",
    "        for cent in range(k):\n",
    "            ptsInClust = dataSet[np.nonzero(clusterAssment[:, 0].A == cent)[0]]\n",
    "            centroids[cent, :] = np.mean(ptsInClust, axis=0)\n",
    "    # centroids：质心矩阵，clusterAssment：每个点的簇的分配结果\n",
    "    return centroids, clusterAssment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datMat = np.mat(loadDataSet('testSet.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.12632757 -3.54832673]\n",
      " [ 1.47861736  1.27753822]\n",
      " [-0.03262045  1.17126921]\n",
      " [ 0.7809183   4.45044345]]\n",
      "[[-0.72175297 -3.03774939]\n",
      " [ 3.36858169  1.49441523]\n",
      " [-2.46571578  2.45059206]\n",
      " [ 1.40656708  3.85884762]]\n",
      "[[-0.83188333 -2.97988206]\n",
      " [ 3.67314583  0.937859  ]\n",
      " [-2.46154315  2.78737555]\n",
      " [ 2.23432133  3.71816925]]\n",
      "[[-1.05611215 -3.00107638]\n",
      " [ 3.6509195  -0.5281174 ]\n",
      " [-2.46154315  2.78737555]\n",
      " [ 2.5212765   3.49464725]]\n",
      "[[-2.79969165 -3.01951378]\n",
      " [ 3.1666855  -2.38897356]\n",
      " [-2.46154315  2.78737555]\n",
      " [ 2.54391447  3.21299611]]\n",
      "[[-3.38237045 -2.9473363 ]\n",
      " [ 2.80293085 -2.7315146 ]\n",
      " [-2.46154315  2.78737555]\n",
      " [ 2.6265299   3.10868015]]\n"
     ]
    }
   ],
   "source": [
    "myCentroids, clustAssing = kMeans(datMat, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二分K-均值算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**算法的伪代码：**  \n",
    "将所有点看成一个簇  \n",
    "当簇数目小于$k$时  \n",
    "&emsp;&emsp;对于每一个簇  \n",
    "&emsp;&emsp;&emsp;&emsp;计算总误差  \n",
    "&emsp;&emsp;&emsp;&emsp;在给定的簇上面进行K-均值聚类($k$=2)  \n",
    "&emsp;&emsp;&emsp;&emsp;计算将该簇一分为二之后的总误差  \n",
    "&emsp;&emsp;选择使得误差最小的那个簇进行划分操作  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataSet: 数据集，k: 簇的数目，distMeas：用来计算距离的函数\n",
    "def biKmeans(dataSet, k, distMeas=distEclud):\n",
    "    # 确定数据集中数据点的总数\n",
    "    m = np.shape(dataSet)[0]\n",
    "    # 创建一个矩阵来存储数据集中每个点的簇分配结果和平方误差\n",
    "    clusterAssment = np.mat(np.zeros((m,2)))\n",
    "    # 计算整个数据集的质心\n",
    "    centroid0 = np.mean(dataSet, axis=0).tolist()[0]\n",
    "    # 使用一个列表保存所有质心\n",
    "    centList =[centroid0]\n",
    "    # 计算每个点到质心的误差值\n",
    "    for j in range(m):#calc initial Error\n",
    "        clusterAssment[j,1] = distMeas(np.mat(centroid0), dataSet[j,:])**2\n",
    "    # 对簇进行划分，直到得到想要的簇数目为止\n",
    "    while (len(centList) < k):\n",
    "        # 将最小的SEE设置为无穷大\n",
    "        lowestSSE = np.inf\n",
    "        for i in range(len(centList)):\n",
    "            # 将该簇中的所有点看成一个小的数据集\n",
    "            ptsInCurrCluster = dataSet[np.nonzero(clusterAssment[:,0].A==i)[0],:]#get the data points currently in cluster i\n",
    "            # 将ptsInCurrCluster输入到函数kMeans()中进行处理k=2，得到两个质心，并给出每个簇的误差值\n",
    "            centroidMat, splitClustAss = kMeans(ptsInCurrCluster, 2, distMeas)\n",
    "            # 计算当前的误差之和\n",
    "            sseSplit = np.sum(splitClustAss[:,1])#compare the SSE to the currrent minimum\n",
    "            # 计算剩余数据集的误差之后\n",
    "            sseNotSplit = np.sum(clusterAssment[np.nonzero(clusterAssment[:,0].A!=i)[0],1])\n",
    "            print(\"sseSplit, and notSplit: \",sseSplit,sseNotSplit)\n",
    "            # 如果划分的SSE值最小，则保留本次划分\n",
    "            if (sseSplit + sseNotSplit) < lowestSSE:\n",
    "                bestCentToSplit = i\n",
    "                bestNewCents = centroidMat\n",
    "                bestClustAss = splitClustAss.copy()\n",
    "                lowestSSE = sseSplit + sseNotSplit\n",
    "        # 得到两个编号为0和1的结果簇，需要将这些簇编号修改为划分簇及新加簇的编号\n",
    "        bestClustAss[np.nonzero(bestClustAss[:,0].A == 1)[0],0] = len(centList) #change 1 to 3,4, or whatever\n",
    "        bestClustAss[np.nonzero(bestClustAss[:,0].A == 0)[0],0] = bestCentToSplit\n",
    "        print('the bestCentToSplit is: ',bestCentToSplit)\n",
    "        print('the len of bestClustAss is: ', len(bestClustAss))\n",
    "        # 新的簇分配结果被更新，新的质心会被添加到centList中\n",
    "        centList[bestCentToSplit] = bestNewCents[0,:].tolist()[0]#replace a centroid with two best centroids \n",
    "        centList.append(bestNewCents[1,:].tolist()[0])\n",
    "        clusterAssment[np.nonzero(clusterAssment[:,0].A == bestCentToSplit)[0],:]= bestClustAss#reassign new clusters, and SSE\n",
    "    return np.mat(centList), clusterAssment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "datMat3 = np.mat(loadDataSet('testSet2.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.35094679  2.2704867 ]\n",
      " [-0.18528081 -1.77306899]]\n",
      "[[-0.48729809  3.42433234]\n",
      " [ 0.30368272 -1.853273  ]]\n",
      "[[-0.06953469  3.29844341]\n",
      " [-0.32150057 -2.62473743]]\n",
      "[[-0.00675605  3.22710297]\n",
      " [-0.45965615 -2.7782156 ]]\n",
      "sseSplit, and notSplit:  453.0334895807502 0.0\n",
      "the bestCentToSplit is:  0\n",
      "the len of bestClustAss is:  60\n",
      "[[-1.06541045  4.32355066]\n",
      " [ 0.32170111  2.01795651]]\n",
      "[[-2.94737575  3.3263781 ]\n",
      " [ 2.93386365  3.12782785]]\n",
      "sseSplit, and notSplit:  77.59224931775066 29.15724944412535\n",
      "[[-1.0764188  -1.40525693]\n",
      " [-0.60261464 -1.9079172 ]]\n",
      "[[-1.3776246  -1.6522424 ]\n",
      " [-0.15366667 -3.15354   ]]\n",
      "[[-1.41084317 -1.873139  ]\n",
      " [-0.05200457 -3.16610557]]\n",
      "[[-1.31198114e+00 -1.96162114e+00]\n",
      " [-7.11923077e-04 -3.21792031e+00]]\n",
      "[[-1.26873575 -2.07139688]\n",
      " [ 0.07973025 -3.24942808]]\n",
      "[[-1.26405367 -2.209896  ]\n",
      " [ 0.19848727 -3.24320436]]\n",
      "[[-1.1836084 -2.2507069]\n",
      " [ 0.2642961 -3.3057243]]\n",
      "[[-1.12616164 -2.30193564]\n",
      " [ 0.35496167 -3.36033556]]\n",
      "sseSplit, and notSplit:  12.753263136887313 423.8762401366249\n",
      "the bestCentToSplit is:  0\n",
      "the len of bestClustAss is:  40\n"
     ]
    }
   ],
   "source": [
    "centList, myNewAssments = biKmeans(datMat3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看质心结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-2.94737575,  3.3263781 ],\n",
       "        [-0.45965615, -2.7782156 ],\n",
       "        [ 2.93386365,  3.12782785]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centList"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
