{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 树回归与标准回归的比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet(fileName):\n",
    "    dataMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        curLine = line.strip().split('\\t')\n",
    "        # 将每行映射成浮点数\n",
    "        fltLine = list(map(float, curLine))\n",
    "        dataMat.append(fltLine)\n",
    "    return dataMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataSet:数据集，feature：待切分的特征，value:该特征的某个值\n",
    "# 将数据按照特征的值来划分\n",
    "def binSplitDataSet(dataSet, feature, value):\n",
    "    mat0 = dataSet[np.nonzero(dataSet[:, feature] > value)[0], :]\n",
    "    mat1 = dataSet[np.nonzero(dataSet[:, feature] <= value)[0], :]\n",
    "    return mat0, mat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成叶子节点\n",
    "def regLeaf(dataSet):\n",
    "    return np.mean(dataSet[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 误差估计函数，计算目标变量的平方误差\n",
    "def regErr(dataSet):\n",
    "    return np.var(dataSet[:, -1]) * np.shape(dataSet)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseBestSplit(dataSet, leafType=regLeaf, errType=regErr, ops=(1, 4)):\n",
    "    # tolS是容许误差下降值， tolN是切分的最少样本数\n",
    "    tolS = ops[0]; tolN = ops[1]\n",
    "    # 如果所有值都相等则退出\n",
    "    if len(set(dataSet[:, -1].T.tolist()[0])) == 1:\n",
    "        return None, leafType(dataSet)\n",
    "    m, n = np.shape(dataSet)\n",
    "    # S：用于与新切分误差对比，来检查新切分是否降低误差\n",
    "    S = errType(dataSet)\n",
    "    bestS = np.inf; bestIndex = 0; bestValue = 0\n",
    "    # 获取最低误差的切分\n",
    "    for featIndex in range(n-1):\n",
    "        for splitVal in set(dataSet[:, featIndex].T.tolist()[0]):\n",
    "            mat0, mat1 = binSplitDataSet(dataSet, featIndex, splitVal)\n",
    "            if (np.shape(mat0)[0] < tolN) or (np.shape(mat1)[0] < tolN): continue\n",
    "            newS = errType(mat0) + errType(mat1)\n",
    "            if newS < bestS:\n",
    "                bestIndex = featIndex\n",
    "                bestValue = splitVal\n",
    "                bestS = newS\n",
    "    # 如果误差减少不大则退出\n",
    "    if (S - bestS) < tolS:\n",
    "        return None, leafType(dataSet)\n",
    "    mat0, mat1 = binSplitDataSet(dataSet, bestIndex, bestValue)\n",
    "    # 如果切分出的数据集很小则退出\n",
    "    if (np.shape(mat0)[0] < tolN) or (np.shape(mat1)[0] < tolN):\n",
    "        return None, leafType(dataSet)\n",
    "    return bestIndex, bestValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 树构建函数\n",
    "def createTree(dataSet, leafType=regLeaf, errType=regErr, ops=(1, 4)):\n",
    "    feat, val = chooseBestSplit(dataSet, leafType, errType, ops)\n",
    "    if feat is None:\n",
    "        return val\n",
    "    retTree = {}\n",
    "    retTree['spInd'] = feat\n",
    "    retTree['spVal'] = val\n",
    "    lSet, rSet = binSplitDataSet(dataSet, feat, val)\n",
    "    retTree['left'] = createTree(lSet, leafType, errType, ops)\n",
    "    retTree['right'] = createTree(rSet, leafType, errType, ops)\n",
    "    return retTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据集格式化成目标变量Y和自变量X\n",
    "def linearSolve(dataSet):\n",
    "    m, n = np.shape(dataSet)\n",
    "    X = np.mat(np.ones((m, n))); Y = np.mat(np.ones((m, 1)))\n",
    "    X[:, 1:n] = dataSet[:, 0:n-1]; Y = dataSet[:, -1]\n",
    "    xTx = X.T * X\n",
    "    if np.linalg.det(xTx) == 0.0:\n",
    "        raise NameError('This matrix is singular, cannot do inverse, try increasing the second value of ops')\n",
    "    # 求ws系数矩阵\n",
    "    ws = xTx.I * (X.T * Y)\n",
    "    return ws, X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelLeaf(dataSet):\n",
    "    ws, X, Y = linearSolve(dataSet)\n",
    "    return ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平方误差\n",
    "def modelErr(dataSet):\n",
    "    ws, X, Y = linearSolve(dataSet)\n",
    "    yHat = X * ws\n",
    "    return np.sum(np.power(Y - yHat, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对回归树叶节点进行预测\n",
    "def regTreeEval(model, inDat):\n",
    "    return float(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对模型树节点进行预测\n",
    "def modelTreeEval(model, inDat):\n",
    "    n = np.shape(inDat)[1]\n",
    "    X = np.mat(np.ones((1, n+1)))\n",
    "    X[:, 1:n+1] = inDat\n",
    "    return float(X * model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试输入变量是否是一棵树\n",
    "def isTree(obj):\n",
    "    return (type(obj).__name__ == 'dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自顶向下遍历整个树，直到命中叶节点为止\n",
    "def treeForeCast(tree, inData, modelEval=regTreeEval):\n",
    "    # 对于单个数据点或者行向量，返回一个预测值\n",
    "    if not isTree(tree): return modelEval(tree, inData)\n",
    "    if inData[tree['spInd']] > tree['spVal']:\n",
    "        if isTree(tree['left']): return treeForeCast(tree['left'], inData, modelEval)\n",
    "        else: return modelEval(tree['left'], inData)\n",
    "    else:\n",
    "        if isTree(tree['right']): return treeForeCast(tree['right'], inData, modelEval)\n",
    "        else: return modelEval(tree['right'], inData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createForeCast(tree, testData, modelEval=regTreeEval):\n",
    "    m = len(testData)\n",
    "    yHat = np.mat(np.zeros((m, 1)))\n",
    "    for i in range(m):\n",
    "        yHat[i, 0] = treeForeCast(tree, np.mat(testData[i]), modelEval)\n",
    "    return yHat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainMat = np.mat(loadDataSet('bikeSpeedVsIq_train.txt'))\n",
    "testMat = np.mat(loadDataSet('bikeSpeedVsIq_test.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTree = createTree(trainMat, ops=(1, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "yHat = createForeCast(myTree, testMat[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.964085231822215"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(yHat, testMat[:, 1], rowvar=0)[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTree = createTree(trainMat, modelLeaf, modelErr, (1, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "yHat = createForeCast(myTree, testMat[:, 0], modelTreeEval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9760412191380629"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(yHat, testMat[:, 1], rowvar=0)[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们知道， $R^2$值越接近1.0越好，所以从上面的结果可以看出，这里模型树的结果比回归树好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws, X, Y = linearSolve(trainMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[37.58916794],\n",
       "        [ 6.18978355]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(np.shape(testMat)[0]):\n",
    "    yHat[i] = testMat[i, 0] * ws[1, 0] + ws[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9434684235674766"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(yHat, testMat[:, 1], rowvar=0)[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标准线性回归在$R^2$值上的表现不如上面两种树回归方法。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
